# This is a readme for the DLAI approach with T5 and GPT language models

## This primarily uses the huggingface library and simpletransformers library (built on hugging face)
- https://huggingface.co/
- https://simpletransformers.ai/

The directories are as follows:

- gpt-j-6b-main, this is the directory used for the paper models
- NASA_NCAT, this is the directory used for the LitCoin challenge
- NERdatasets, this is additional training sets for the NASA_NCAT challenge
- scifive, this was a quick test to get the scifive model running, results were poor