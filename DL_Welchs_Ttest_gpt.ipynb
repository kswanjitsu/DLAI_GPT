{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import t\n",
    "#import pandas as pd\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# to see variance of both samples pre and post-substitution\n",
    "cols = ['old_document', 'new_document', 'old_fk_score','new_fk_score','old_fk_grade','new_fk_grade', 'old_dc_score',\n",
    "        'new_dc_score','old_cl_score','new_cl_score','old_ar_index','new_ar_index', 'old_smog_score', 'new_smog_score',\n",
    "        'old_gf_index', 'new_gf_index']\n",
    "\n",
    "#'/home/karl/PycharmProjects/DLAI/translate/prold_pipeline_results_graded.txt' - for prog+ai\n",
    "with open('/home/karl/PycharmProjects/DLAI_GPT/gpt-j-6b-main/pipeline_results_graded.txt', encoding='utf-8-sig') as data:\n",
    "    df = pd.read_csv(data,  sep='|',names=cols).reset_index()\n",
    "    df = df.drop(['index'], axis=1)\n",
    "    df = df.drop([0])\n",
    "    df['old_fk_score'] = df['old_fk_score'].apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "    df['new_fk_score'] = df['new_fk_score'].apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "    df['old_fk_grade'] = df['old_fk_grade'].apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "    df['new_fk_grade'] = df['new_fk_grade'].apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "    df['old_dc_score'] = df['old_dc_score'].apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "    df['new_dc_score'] = df['new_dc_score'].apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "    df['old_cl_score'] = df['old_cl_score'].apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "    df['new_cl_score'] = df['new_cl_score'].apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "    df['old_ar_index'] = df['old_ar_index'].apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "    df['new_ar_index'] = df['new_ar_index'].apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "    df['old_smog_score'] = df['old_smog_score'].apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "    df['new_smog_score'] = df['new_smog_score'].apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "    df['old_gf_index'] = df['old_gf_index'].apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "    df['new_gf_index'] = df['new_gf_index'].apply(lambda col:pd.to_numeric(col, errors='coerce'))\n",
    "\n",
    "    #x_simple = np.array(((df[\"new_fk_score\"] - df[\"old_fk_score\"]) / df['old_fk_score']) * 100)\n",
    "    #y_simple = np.array(df[\"old_fk_score\"])\n",
    "    #n, bins, patches = plt.hist(y_simple, bins=100)\n",
    "    #plt.show()\n",
    "    #plt.savefig('/home/karl/Pictures/old.png')\n",
    "\n",
    "    #x_simple = np.array(df[\"new_fk_score\"])\n",
    "    #n, bins, patches = plt.hist(x_simple, bins=100)\n",
    "    #plt.show()\n",
    "    #plt.savefig('/home/karl/Pictures/new.png')\n",
    "\n",
    "    #my_rho = np.corrcoef(x_simple, y_simple)\n",
    "    #print(\"Correlation = \" + str(my_rho[0,1]))\n",
    "    #fig, ax = plt.subplots()\n",
    "    #ax.scatter(x_simple, y_simple)\n",
    "    #ax.set_title(\"Correlation = \" + str(my_rho[0,1]))\n",
    "    #plt.show()\n",
    "    #plt.savefig('/home/karl/Pictures/correlation.png')\n",
    "\n",
    "# Here we see variance is about the same so the pipeline is effectively swapping the words needed and not\n",
    "# swapping words, inappropriately per the rules of the pipeline. Additionally, we can use a t-test as variance is low.\n",
    "# However, there is a small difference in SD for each sample pre-and-post sub, so we use a Welch T-test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df2 = df\n",
    "df2 = df2.drop(['old_document', 'new_document', 'old_dc_score', 'new_dc_score', 'old_cl_score', 'new_cl_score', 'old_smog_score', 'new_smog_score'], axis=1)\n",
    "df2.to_csv('gpt_scores_table_for_box_plot.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "old_document        object\nnew_document        object\nold_fk_score       float64\nnew_fk_score       float64\nold_fk_grade       float64\nnew_fk_grade       float64\nold_dc_score       float64\nnew_dc_score       float64\nold_cl_score       float64\nnew_cl_score       float64\nold_ar_index       float64\nnew_ar_index       float64\nold_smold_score    float64\nnew_smold_score    float64\nold_gf_index       float64\nnew_gf_index       float64\ndtype: object"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import t\n",
    "import pandas as pd\n",
    "\n",
    "def welch_ttest(x1, x2,alternative):\n",
    "    std1 = x1.std()\n",
    "    std2 = x2.std()\n",
    "    n1 = x1.size\n",
    "    n2 = x2.size\n",
    "    m1 = np.mean(x1)\n",
    "    m2 = np.mean(x2)\n",
    "\n",
    "    v1 = np.var(x1, ddof=1)\n",
    "    v2 = np.var(x2, ddof=1)\n",
    "\n",
    "    pooled_se = np.sqrt(v1 / n1 + v2 / n2)\n",
    "    delta = m1-m2\n",
    "\n",
    "    tstat = delta /  pooled_se\n",
    "    df = (v1 / n1 + v2 / n2)**2 / (v1**2 / (n1**2 * (n1 - 1)) + v2**2 / (n2**2 * (n2 - 1)))\n",
    "\n",
    "    # two side t-test\n",
    "    p = 2 * t.cdf(-abs(tstat), df)\n",
    "\n",
    "    # upper and lower bounds\n",
    "    lb = delta - t.ppf(0.975,df)*pooled_se\n",
    "    ub = delta + t.ppf(0.975,df)*pooled_se\n",
    "\n",
    "    result_list = [m2, m1, tstat,p,delta,lb,ub, std1, std2]\n",
    "    return  result_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[35.59366044985741,\n 67.2306354978077,\n 14.00548419460426,\n 1.3749893157749472e-41,\n 31.636975047950287,\n 27.205448823043643,\n 36.068501272856935,\n 49.33637589411156,\n 34.91992954550203]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns=['Pre-sub mean', 'Post-sub mean', 'T-statistic','p-value 2 sided','Difference in mean','CI lower bound','CI upper bound', 'Pre-sub STD', 'Post-sub STD'])\n",
    "\n",
    "\n",
    "ts1 = df['new_fk_score']\n",
    "ts2 = df[\"old_fk_score\"]\n",
    "fk_score_stats = welch_ttest(ts1,ts2,\"equal\")\n",
    "fk_score_stats\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[10.752294288683798,\n 5.8972302962476935,\n -13.986481264076321,\n 1.990015003723007e-41,\n -4.855063992436104,\n -5.536071758633763,\n -4.174056226238446,\n 7.6810908992565565,\n 5.222647635382556]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts3 = df['new_fk_grade']\n",
    "ts4 = df[\"old_fk_grade\"]\n",
    "fk_grade_stats = welch_ttest(ts3,ts4,\"equal\")\n",
    "fk_grade_stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[12.527905237874613,\n 14.627330327245245,\n 14.033291292147268,\n 6.043602669836232e-42,\n 2.099425089370632,\n 1.8059533907688317,\n 2.392896787972432,\n 3.05015194543767,\n 2.5925759844972216]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1 = df['new_dc_score']\n",
    "ts2 = df[\"old_dc_score\"]\n",
    "dc_score_stats = welch_ttest(ts1,ts2,\"equal\")\n",
    "dc_score_stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[-8.115293654786043,\n -41.63259287074375,\n -12.415900971448082,\n 1.910734659422187e-33,\n -33.517299215957706,\n -38.81348790917936,\n -28.221110522736055,\n 60.28609923529347,\n 39.7928649803151]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1 = df['new_cl_score']\n",
    "ts2 = df[\"old_cl_score\"]\n",
    "cl_score_stats = welch_ttest(ts1,ts2,\"equal\")\n",
    "cl_score_stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[12.703499952377719,\n 2.3702420603910417,\n -26.358970525306525,\n 4.077199695168121e-124,\n -10.333257891986676,\n -11.102285857267223,\n -9.56422992670613,\n 8.18589531222071,\n 6.559426266374294]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1 = df['new_ar_index']\n",
    "ts2 = df[\"old_ar_index\"]\n",
    "ar_score_stats= welch_ttest(ts1,ts2,\"equal\")\n",
    "ar_score_stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[64.53037327684274,\n 51.10196450195839,\n -10.570639949727353,\n 3.9966969855257213e-25,\n -13.428408774884346,\n -15.920536690187095,\n -10.936280859581597,\n 27.31387891113477,\n 20.23423821963918]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1 = df['new_smold_score']\n",
    "ts2 = df[\"old_smold_score\"]\n",
    "smold_score_stats = welch_ttest(ts1,ts2,\"equal\")\n",
    "smold_score_stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[23.107863430035497,\n 19.299696583615304,\n -10.101895504264862,\n 3.6490740612914545e-23,\n -3.8081668464201925,\n -4.547701053489555,\n -3.06863263935083,\n 8.0772847699553,\n 6.04223423021072]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1 = df['new_gf_index']\n",
    "ts2 = df[\"old_gf_index\"]\n",
    "gf_score_stats = welch_ttest(ts1,ts2,\"equal\")\n",
    "gf_score_stats\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "         GPT Approach                FK Score               FK Grade  \\\n0        Pre-sub mean       35.59366044985741     10.752294288683798   \n1       Post-sub mean        67.2306354978077     5.8972302962476935   \n2         T-statistic       14.00548419460426    -13.986481264076321   \n3     p-value 2 sided  1.3749893157749472e-41  1.990015003723007e-41   \n4  Difference in mean      31.636975047950287     -4.855063992436104   \n5      CI lower bound      27.205448823043643     -5.536071758633763   \n6      CI upper bound      36.068501272856935     -4.174056226238446   \n7         Pre-sub STD       49.33637589411156     7.6810908992565565   \n8        Post-sub STD       34.91992954550203      5.222647635382556   \n\n                 AR index                GF index  \n0      12.703499952377719      23.107863430035497  \n1      2.3702420603910417      19.299696583615304  \n2     -26.358970525306525     -10.101895504264862  \n3  4.077199695168121e-124  3.6490740612914545e-23  \n4     -10.333257891986676     -3.8081668464201925  \n5     -11.102285857267223      -4.547701053489555  \n6       -9.56422992670613       -3.06863263935083  \n7        8.18589531222071         8.0772847699553  \n8       6.559426266374294        6.04223423021072  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GPT Approach</th>\n      <th>FK Score</th>\n      <th>FK Grade</th>\n      <th>AR index</th>\n      <th>GF index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pre-sub mean</td>\n      <td>35.59366044985741</td>\n      <td>10.752294288683798</td>\n      <td>12.703499952377719</td>\n      <td>23.107863430035497</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Post-sub mean</td>\n      <td>67.2306354978077</td>\n      <td>5.8972302962476935</td>\n      <td>2.3702420603910417</td>\n      <td>19.299696583615304</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>T-statistic</td>\n      <td>14.00548419460426</td>\n      <td>-13.986481264076321</td>\n      <td>-26.358970525306525</td>\n      <td>-10.101895504264862</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>p-value 2 sided</td>\n      <td>1.3749893157749472e-41</td>\n      <td>1.990015003723007e-41</td>\n      <td>4.077199695168121e-124</td>\n      <td>3.6490740612914545e-23</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Difference in mean</td>\n      <td>31.636975047950287</td>\n      <td>-4.855063992436104</td>\n      <td>-10.333257891986676</td>\n      <td>-3.8081668464201925</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>CI lower bound</td>\n      <td>27.205448823043643</td>\n      <td>-5.536071758633763</td>\n      <td>-11.102285857267223</td>\n      <td>-4.547701053489555</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>CI upper bound</td>\n      <td>36.068501272856935</td>\n      <td>-4.174056226238446</td>\n      <td>-9.56422992670613</td>\n      <td>-3.06863263935083</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Pre-sub STD</td>\n      <td>49.33637589411156</td>\n      <td>7.6810908992565565</td>\n      <td>8.18589531222071</td>\n      <td>8.0772847699553</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Post-sub STD</td>\n      <td>34.91992954550203</td>\n      <td>5.222647635382556</td>\n      <td>6.559426266374294</td>\n      <td>6.04223423021072</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"GPT Approach\": ['Pre-sub mean', 'Post-sub mean', 'T-statistic','p-value 2 sided','Difference in mean','CI lower bound','CI upper bound', 'Pre-sub STD', 'Post-sub STD'],\n",
    "     \"FK Score\" : fk_score_stats,\n",
    "     \"FK Grade\" : fk_grade_stats,\n",
    "     \"AR index\" : ar_score_stats,\n",
    "     \"GF index\" : gf_score_stats\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=d).astype(str)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df.to_csv(\"GPT_table2_for_paper.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}